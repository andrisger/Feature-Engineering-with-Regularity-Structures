{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso, LassoLars, LassoLarsCV, Ridge, LassoCV, RidgeCV, HuberRegressor\n",
    "from sklearn.linear_model import LinearRegression as lin_reg\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import scipy.interpolate as interpolate\n",
    "\n",
    "err1 = lambda x, y: np.sqrt(MAE(x,y))\n",
    "err2 = lambda x, y: np.sqrt(MSE(x,y))\n",
    "\n",
    "Error1 = lambda x, y: err1(x,y)/err1(np.zeros(y.shape), y)\n",
    "Error2 = lambda x, y: err2(x,y)/err2(np.zeros(y.shape), y)\n",
    "\n",
    "%run SPDEs.ipynb\n",
    "%run Rule.ipynb\n",
    "%run Model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for performing Algorithm 2 \n",
    "\n",
    "class IML():\n",
    "    \n",
    "    def __init__(self, Solutions, Rule, height, deg, eps = 1, step = 1, Noise = None, diff = True, train = None, test = None, trees = None, T = None, X = None):\n",
    "        \n",
    "        if type(Solutions) == pd.core.frame.DataFrame:\n",
    "            n = Solutions.columns.levshape[0]\n",
    "            self.Sol = [Solutions['S'+str(i+1)] for i in range(n)]\n",
    "            self.T = np.array(self.Sol[0].index).astype(np.float64) # time grid (O_T)\n",
    "            self.X = np.array(self.Sol[0].columns).astype(np.float64) # space grid (O_X)\n",
    "        else:\n",
    "            self.Sol = Solutions # set the solutions\n",
    "            self.T = T\n",
    "            self.X = X\n",
    "            \n",
    "        self.R = Rule \n",
    "        self.H = height\n",
    "        self.deg = deg\n",
    "        self.step = step # Discretization of the time step [0,\\delta]. Set to be 1 by default\n",
    "        self.diff = diff # True if derivatives are present in the model.\n",
    "        self.train = train # Indices of the train set (U^{obs})\n",
    "        self.test = test # Indices of the test set (U^{pr})\n",
    "        self.trees = trees # Model's feature set\n",
    "        self.Pred = None # u^{pr} \n",
    "        self.cut_off_size = 3 # If the prediction starts to blow up cut of prediction at 3*maximum(|Solutions|)\n",
    "        self.max = max([np.abs(A).max().max() for A in self.Sol]) \n",
    "        self.M_train = [] # placeholder for the models for the train set. (All time points simultaneously)\n",
    "        self.M_test = [] # placeholder for the models for the test set\n",
    "        self.regression_fit = {x: None for x in self.X} # placeholder for linear fit at each space point\n",
    "        self.Type = \"Parabolic\" # type od PDE. Set to Parabolic by default \n",
    "        self.BC = \"P\" # Boundary conditions. Set to Periodic by default\n",
    "        self.eps = eps # viscosity\n",
    "        self.noise = Noise\n",
    "    \n",
    "    def set_train_test(self, train = None, test = None, test_size = 0.3):\n",
    "        \n",
    "        # Create a random test/train split of Solutions if it is not given\n",
    "        \n",
    "        if train is not None:\n",
    "            self.train = train\n",
    "            if test is None:\n",
    "                self.test = [a for a in np.arange(len(self.Sol)) if a not in train]\n",
    "            else:\n",
    "                self.test = test\n",
    "        elif test is not None:\n",
    "            self.test = test\n",
    "            self.train = [a for a in np.arange(len(self.Sol)) if a not in test]\n",
    "        else:\n",
    "            self.train, self.test = train_test_split(np.arange(len(self.Sol), test_size))\n",
    "    \n",
    "    def set_trees(self, trees = None):\n",
    "                                                     \n",
    "        # If set of trees in the model is not given create a small toy model and extract trees from there\n",
    "        if trees is None:\n",
    "                W_toy = np.zeros((1, 2, 2))\n",
    "                if self.Type in {'P', 'Parabolic'}:\n",
    "                    I = SPDE(X = [0,1], T = [0,1]).Integrate_Parabolic_trees\n",
    "                elif self.Type in {'W','Wave'}:\n",
    "                    I = SPDE(X = [0,1], T = [0,1]).Integrate_Wave_trees\n",
    "                M_toy = Model(I, self.R, self.H, self.deg, derivative = self.diff)\n",
    "                # In this experiment only extra trees that are allowed are derivatives of I_c[u_0]\n",
    "                # One should generalize this part in order to apply Algorithm 2 to a Wave Equation with zero forcing and \"random\" initial conditions\n",
    "                if self.diff: \n",
    "                    M_toy.create_model_list(W_toy, dt = 1, lollipops = W_toy, diff = False, extra_planted = W_toy, extra_deg = -0.5, key = \"I'[xi]\")\n",
    "                    self.trees = list(M_toy.models[0].keys())\n",
    "                else:\n",
    "                    M_toy.create_model_list(W_toy, dt = 1, lollipops = W_toy, diff = False)\n",
    "                    self.trees = list(M_toy.models[0].keys())\n",
    "        else:\n",
    "            self.trees = trees\n",
    "    \n",
    "    def initialize_Predictions(self):\n",
    "        self.Pred = np.zeros((len(self.T),len(self.X),len(self.test)))\n",
    "        # Set initial condition of the predictions to be the known vsalues of the solutions from test set\n",
    "        self.Pred[0] = self.Sol[self.test, 0, :].T\n",
    "        \n",
    "    def cut_off(self, vec): # Cut off fucnction that kills too big values if the algorith blows up\n",
    "        Max = self.cut_off_size*self.max\n",
    "        \n",
    "        f = np.vectorize(lambda x: 1*(np.abs(x) < Max))\n",
    "        \n",
    "        return vec*f(vec)+Max*np.sign(vec)*(np.abs(vec) >= Max)\n",
    "    \n",
    "    def new_model(self, start, Prediction = None, T = None, X = None, test = None, train = [], time_grid_num = 10, space_interpolation = 1):\n",
    "        \n",
    "        # Creates models for a given set of initial conditions\n",
    "        \n",
    "        if Prediction is None: Prediction = self.Pred\n",
    "        if T is None: T = self.T\n",
    "        if X is None: X = self.X\n",
    "        if test is None: test = self.test\n",
    "        if train is None: train = self.train\n",
    "        \n",
    "        X_ = np.linspace(X[0], X[-1], space_interpolation*(len(X)-1)+1)\n",
    "        l, dx, dt = len(test) + len(train), X_[1]-X_[0], T[1]-T[0]\n",
    "        IC = np.zeros((l, len(X_)))\n",
    "        if train == []: # By default only compute models for the initial conditons (u^pr_{t_k}) from test set\n",
    "            IC = interpolate.interp1d(X, self.cut_off(Prediction[start].T))(X_)\n",
    "        else: # Compute models for both train and test sets at this initial conditions\n",
    "            IC[train] = interpolate.interp1d(X, self.Sol[train, start, :])(X_)\n",
    "            IC[test] = interpolate.interp1d(X, self.cut_off(Prediction[start].T))(X_)\n",
    "        \n",
    "        time_grid = np.linspace(T[start], T[start+self.step], time_grid_num+1) \n",
    "        W_ = np.zeros((l, time_grid_num+1, len(X_))) # No noise is present. \n",
    "        \n",
    "        # Compute I_c[u^pr_{t_k}]. Symbolically these will still be denoted by I[xi] in the model.\n",
    "        lollipop = SPDE(Type = self.Type, BC = self.BC, eps = self.eps, IC = IC).Parabolic(W_, time_grid, X_)\n",
    "        \n",
    "        # Add \\partial_c I_c[u^pr_{t_k}] which will be symbolically denoted by I'[xi]\n",
    "        if self.diff:\n",
    "            lollipop_diff = [SPDE().discrete_diff(lol, N = len(X_), flatten=False, higher = False)/dx for lol in lollipop]\n",
    "        \n",
    "        # Initialize integration map I\n",
    "        I = SPDE(eps = self.eps, BC = self.BC, X = X_, T = time_grid).Integrate_FFT_trees\n",
    "        \n",
    "        # initialize model class\n",
    "        M = Model(I, self.R, self.H, self.deg, derivative = self.diff)\n",
    "        # create models\n",
    "        if self.diff: \n",
    "            M.create_model_list(W_, dt = dt/time_grid_num, diff=False, lollipops = lollipop, extra_planted = lollipop_diff, extra_deg = -0.5, key = \"I'[xi]\")\n",
    "        else:\n",
    "            M.create_model_list(W_, dt = dt/time_grid_num, diff=False, lollipops = lollipop)\n",
    "            \n",
    "        \n",
    "        if space_interpolation > 1:                      \n",
    "            return [{tree: model[tree][:,::space_interpolation] for tree in model} for model in M.models]\n",
    "        else:\n",
    "            return M.models\n",
    "\n",
    "\n",
    "    # Create models for training. (Step 1 of Algorith 2)\n",
    "    def training_models(self, T = None, X = None, train = None, time_grid_num = 10):\n",
    "        \n",
    "        if T is None: T = self.T\n",
    "        if X is None: X = self.X\n",
    "        if train is None: train = self.train\n",
    "        \n",
    "        dt, dx = T[1]-T[0], X[1]-X[0]\n",
    "        time_grid = np.linspace(0,dt,time_grid_num+1)\n",
    "        \n",
    "        # Setting initial conditions as u^1_{t_0}, u^1_{t_1}, ..., u^1_{t_{N-1}}, u^2_{t_0}, ... u^m_{t_{N-1}}\n",
    "        # where m is the number of solutions in the training set, N = len(T) . Overall m*(N-1) initial conditions\n",
    "        \n",
    "        # Initializing IC\n",
    "        IC = np.array([self.Sol[u, i, :] for u in train for i in range(len(T)-1)]).astype('float32')\n",
    "\n",
    "        W_ = np.zeros((IC.shape[0], time_grid_num+1, len(X))).astype('float32') # No noise is present.\n",
    "        \n",
    "        # Compute I_c[u_{t_k}]. Symbolically these will still be denoted by I[xi] in the model.\n",
    "        \n",
    "        lollipop = SPDE(Type = self.Type, BC = self.BC, eps = self.eps, IC = IC).Parabolic(W_, time_grid, X)\n",
    "        \n",
    "        # Initialize integration map I\n",
    "        I = SPDE(eps = self.eps, BC = self.BC, X = self.X, T = time_grid).Integrate_FFT_trees\n",
    "        \n",
    "        # Add \\partial_c I_c[u^pr_{t_k}] which will be symbolically denoted by I'[xi]\n",
    "        if self.diff:\n",
    "            lollipop_diff = [SPDE().discrete_diff(lol, N = len(X), flatten=False, higher = False).astype('float32')/dx for lol in lollipop]\n",
    "\n",
    "        M = Model(I, self.R, self.H, self.deg, derivative = self.diff)\n",
    "        \n",
    "        print(\"Creating Model\")\n",
    "        \n",
    "        if self.diff: \n",
    "            M.create_model_list(W_, dt = dt/time_grid_num, diff=False, lollipops = lollipop, extra_planted = lollipop_diff, extra_deg = -0.5, key = \"I'[xi]\")\n",
    "        else:\n",
    "            M.create_model_list(W_, dt = dt/time_grid_num, diff=False, lollipops = lollipop)\n",
    "            \n",
    "        self.M_train = M.models\n",
    "        \n",
    "    # Fit linear regresion for each space point. (Step 2 of Algorithm 2)\n",
    "    def fit_training_model(self, T = None, X = None, train = None, trees = None, alg = lin_reg(), prepro = False):\n",
    "        if T is None: T = self.T\n",
    "        if X is None: X = self.X\n",
    "        if train is None: train = self.train\n",
    "        if trees is None: trees = self.trees\n",
    "        \n",
    "        # Labels\n",
    "        y = np.array([self.Sol[u, i, :] for u in train for i in range(1,len(T))])\n",
    "        # Features\n",
    "        x = np.array([np.array([Mu[m][-1] for m in trees]) for Mu in self.M_train])\n",
    "        \n",
    "        for i in tqdm(range(len(X))):\n",
    "            x_ = x[:,:,i]\n",
    "            y_ = y[:,i]\n",
    "            if prepro: # normalise data if needed\n",
    "                scaler = preprocessing.StandardScaler().fit(x_)\n",
    "                x = scaler.transform(x_)\n",
    "            self.regression_fit[X[i]] = alg.fit(x_, y_) # fit regression at the space point X_i\n",
    "    \n",
    "    # Given model for u^pr_{t_k} make a prediction of u^pr_{t_{k+1}} using linear fit created above\n",
    "    # This is an iterative substep for a given k of Step 3 & 4 of Algorithm 2.\n",
    "    def predict_with_fitted(self, k, M, Prediction = None, T = None, X = None, trees = None, test = None, train = None, prepro = False):          \n",
    "    \n",
    "        if Prediction is None: Prediction = self.Pred\n",
    "        if T is None: T = self.T\n",
    "        if X is None: X = self.X\n",
    "        if trees is None: trees = self.trees\n",
    "        if test is None: test = self.test\n",
    "        if train is None: train = self.train\n",
    "        \n",
    "        # Given model Mu of u^pr_{t_k} for each u^pr frm test set extract all the space points\n",
    "        # of the models at time \\delta.\n",
    "        x = np.array([np.array([Mu[m][-1] for m in trees]) for Mu in M])\n",
    "        \n",
    "        # Predict solution for each space point\n",
    "        for i in range(len(X)):\n",
    "            x_ = x[:,:,i] # model point at the time-space point (\\delta, x_i)\n",
    "            if prepro: # normalise data if needed\n",
    "                scaler = preprocessing.StandardScaler().fit(x_)\n",
    "                x = scaler.transform(x_)\n",
    "            \n",
    "            # prediction\n",
    "            Prediction[k+1][i] = self.cut_off(self.regression_fit[X[i]].predict(x_)).flatten() \n",
    "        \n",
    "        # Force the prediction to be periodic\n",
    "        temp = (Prediction[k+1][0] + Prediction[k+1][len(X) - 1])/2\n",
    "        Prediction[k+1][0] = temp\n",
    "        Prediction[k+1][len(X) - 1] = temp\n",
    "    \n",
    "    # Step 3 and 4 of the Algorithm 2.\n",
    "    def learn_with_fitted(self, start = None, end = None, past = True, Prediction = None, T = None, X = None, trees = None, test = None, train = None, alg = lin_reg(), prepro = False, space_interpolation = 1, save_models=False):\n",
    "        \n",
    "        if Prediction is None:\n",
    "            if self.Pred is None:\n",
    "                self.initialize_Predictions()\n",
    "                Prediction = self.Pred\n",
    "            else:\n",
    "                Prediction = self.Pred\n",
    "            \n",
    "        if T is None: T = self.T\n",
    "        if X is None: X = self.X\n",
    "        if start is None: start = 0\n",
    "        if end is None: end = len(T)-1 \n",
    "        if trees is None: trees = self.trees\n",
    "        if test is None: test = self.test\n",
    "        if train is None: train = self.train\n",
    "        \n",
    "        for k in range(start, end):\n",
    "            if not save_models and len(self.M_test) > 1: self.M_test.pop()\n",
    "            # Create models for u^pr_{t_k}\n",
    "            self.M_test.append(self.new_model(k, Prediction, T, X, test, train = [], space_interpolation = space_interpolation))\n",
    "            \n",
    "            # Predict u^pr_{t_{k+1}}\n",
    "            self.predict_with_fitted(k, self.M_test[-1], Prediction, T, X, trees, test, train, prepro)\n",
    "            \n",
    "    def to_df_list(self):\n",
    "        predicted = [pd.DataFrame(index = self.T, columns = self.X) for _ in range(len(self.test))]\n",
    "\n",
    "        for i in range(len(self.T)):\n",
    "            curr = self.Pred[i].T\n",
    "            for j in range(len(self.test)):\n",
    "                predicted[j].iloc[i] = curr[j]\n",
    "        \n",
    "        return predicted\n",
    "    \n",
    "    def to_df_df(self):\n",
    "        \n",
    "        predicted = self.to_df_list()\n",
    "        columns = pd.MultiIndex.from_product([[\"S\"+str(i+1) for i in self.test], self.X])       \n",
    "        Predicted = pd.DataFrame(index = predicted[0].index, columns = columns)\n",
    "        for i, a in enumerate(self.test):\n",
    "            Predicted[\"S\"+str(a+1)] = predicted[i]\n",
    "        \n",
    "        return Predicted\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
