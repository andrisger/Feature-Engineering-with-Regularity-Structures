{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso, LassoLars, LassoLarsCV, Ridge, LassoCV, RidgeCV, HuberRegressor\n",
    "from sklearn.linear_model import LinearRegression as lin_reg\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "err1 = lambda x, y: np.sqrt(mean_absolute_error(x,y))\n",
    "err2 = lambda x, y: np.sqrt(mean_squared_error(x,y))\n",
    "\n",
    "Error1 = lambda x, y: err1(x,y)/err1(np.zeros(y.shape), y)\n",
    "Error2 = lambda x, y: err2(x,y)/err2(np.zeros(y.shape), y)\n",
    "\n",
    "%run Classes/SPDEs.ipynb\n",
    "%run Classes/Rule.ipynb\n",
    "%run Classes/Model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class summary():\n",
    "    \n",
    "    def __init__(self, test):\n",
    "        \n",
    "        self.test = test\n",
    "    \n",
    "    def time_comparison(self, k, t, Solution, Prediction, error = Error2, title = True):\n",
    "        # Draw graphs of the k-th solution and the prediction at time t. X-axis: space grid. Y-axis: values.\n",
    "        fig = plt.figure(figsize=(8, 6))\n",
    "        if type(Solution) in {list, np.array}:\n",
    "            T = Solution[0].index\n",
    "            Solution[self.test[k]].iloc[t].plot(color = 'b', label = \"Solution at time {}.\".format(T[t]))\n",
    "            S = Solution[self.test[k]].iloc[t].values\n",
    "        else:\n",
    "            T = Solution.index\n",
    "            Solution[\"S\"+str(self.test[k]+1)].iloc[t].plot(color = 'b', label = \"Solution at time {}.\".format(T[t]))\n",
    "            S = Solution[\"S\"+str(self.test[k]+1)].iloc[t].values\n",
    "        if type(Prediction) in {list, np.array}:\n",
    "            Prediction[k].iloc[t].plot(color = 'r', label = \"Prediction at time {}.\".format(T[t]))\n",
    "            P = Prediction[k].iloc[t].values\n",
    "        else:\n",
    "            Prediction[\"S\"+str(self.test[k]+1)].iloc[t].plot(color = 'r', label = \"Prediction at time {}.\".format(T[t]))\n",
    "            P = Prediction[\"S\"+str(self.test[k]+1)].iloc[t].values\n",
    "        plt.xlabel('Space')\n",
    "        plt.ylabel('Value')\n",
    "        if title:\n",
    "            plt.title(\"Solution and Prediction of the test case {}, at time point number {}.\".format(k+1,t))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Error between solution and prediction at time {} is : {}.\".format(T[t], error(P,S)))\n",
    "        \n",
    "    def space_comparison(self, k, x, Solution, Prediction, error = Error2, title = True):\n",
    "        # Draw graphs of the k-th solution and the prediction at space point x. X-axis: time grid. Y-axis: values.\n",
    "        fig = plt.figure(figsize=(8, 6))\n",
    "        if type(Solution) in {list, np.array}:\n",
    "            X = Solution[0].columns\n",
    "            Solution[self.test[k]][X[x]].plot(color = 'b', label = \"Solution at space point {}.\".format(X[x]))\n",
    "            S = Solution[self.test[k]][X[x]].values\n",
    "        else:\n",
    "            X = Solution[\"S1\"].columns\n",
    "            Solution[\"S\"+str(self.test[k]+1)][X[x]].plot(color = 'b', label = \"Solution at space point {}.\".format(X[x]))\n",
    "            S = Solution[\"S\"+str(self.test[k]+1)][X[x]].values\n",
    "        if type(Prediction) in {list, np.array}:\n",
    "            Prediction[k][X[x]].plot(color = 'r', label = \"Prediction at space point {}.\".format(X[x]))\n",
    "            P = Prediction[k][X[x]].values\n",
    "        else:\n",
    "            Prediction[\"S\"+str(self.test[k]+1)][X[x]].plot(color = 'r', label = \"Prediction at space point {}.\".format(X[x]))\n",
    "            P = Prediction[\"S\"+str(self.test[k]+1)][X[x]].values\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Value')\n",
    "        if title:\n",
    "            plt.title(\"Solution and Prediction of the test case {}, at space point number {}.\".format(k+1,x))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Error between solution and prediction at space point {} is : {}.\".format(X[x], error(P,S)))\n",
    "        \n",
    "    def full_comparison(self, k, Solution, Prediction, error = Error2, cmap = \"coolwarm\", show_title = True):\n",
    "        \n",
    "        # Heatmaps of k-th solution and prediction. All space-time values\n",
    "        \n",
    "        if type(Solution) in {list, np.array}:\n",
    "            S = Solution[self.test[k]].values\n",
    "        else:\n",
    "            S = Solution[\"S\"+str(self.test[k]+1)].values\n",
    "        if type(Prediction) in {list, np.array}:\n",
    "            P = Prediction[k].values\n",
    "        else:\n",
    "            P = Prediction[\"S\"+str(self.test[k]+1)].values\n",
    "        \n",
    "        er = error(P, S)\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        if show_title:\n",
    "            fig.suptitle('Heatmaps for solution and prediction. Test case {}. Relative l2 error: {}'.format(k+1 ,round(er,4)))\n",
    "            axs[0].set_title(\"Solution\", fontsize = 15)\n",
    "            axs[1].set_title(\"Prediction\", fontsize = 15)\n",
    "            \n",
    "        sns.color_palette(cmap, as_cmap=True)\n",
    "        sns.heatmap(np.array(S.T).astype(np.float64), ax=axs[0], \n",
    "                    xticklabels=20, yticklabels=40, cmap = cmap)\n",
    "        axs[0].set_xlabel('Time', fontsize = 15)\n",
    "        axs[0].set_ylabel('Space', fontsize = 15)\n",
    "        sns.heatmap(np.array(P.T).astype(np.float64), ax=axs[1], \n",
    "                    xticklabels=20, yticklabels=40, cmap = cmap)\n",
    "        axs[1].set_xlabel('Time', fontsize = 15)\n",
    "        axs[1].set_ylabel('Space', fontsize = 15)\n",
    "        plt.show();\n",
    "        if show_title is False:\n",
    "            print('Error:', er)\n",
    "        \n",
    "    def errors_comparison(self, k, Solution, Prediction, error = Error2, cmap = \"coolwarm\", show_title = False):\n",
    "        \n",
    "        # Heatmaps for the errors of the k-th solution and prediction.\n",
    "        \n",
    "        if type(Solution) in {list, np.array}:\n",
    "            S = Solution[self.test[k]].values\n",
    "        else:\n",
    "            S = Solution[\"S\"+str(self.test[k]+1)].values\n",
    "        if type(Prediction) in {list, np.array}:\n",
    "            P = Prediction[k].values\n",
    "        else:\n",
    "            P = Prediction[\"S\"+str(self.test[k]+1)].values\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        if show_title:\n",
    "            fig.suptitle('Heatmaps for Absolute Errors and Relative l2 error of each point.')\n",
    "        sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "        sns.heatmap(np.abs(np.array((S-P).T).astype(np.float64)), ax=axs[0], \n",
    "                    xticklabels=20, yticklabels=40, cmap = cmap);\n",
    "        axs[0].set_title(\"Absolute Errors\", fontsize = 15)\n",
    "        axs[0].set_xlabel('Time', fontsize = 15)\n",
    "        axs[0].set_ylabel('Space', fontsize = 15)\n",
    "        std = (S-P)**2/S**2\n",
    "        std = np.sqrt(np.array(std.T).astype(np.float64))\n",
    "        \n",
    "        sns.heatmap(std, ax=axs[1], xticklabels=20, yticklabels=40, cmap = cmap);\n",
    "        axs[1].set_title(\"Relative l2 error at every point\", fontsize = 15)\n",
    "        axs[1].set_xlabel('Time', fontsize = 15)\n",
    "        axs[1].set_ylabel('Space', fontsize = 15)\n",
    "        plt.show()\n",
    "        \n",
    "    def one_error(self, k, Solution, Prediction, error = Error2):\n",
    "        \n",
    "        # Compute the error between the k-th solution and prediction\n",
    "        \n",
    "        if type(Solution) in {list, np.array}:\n",
    "            S = Solution[self.test[k]].values\n",
    "        else:\n",
    "            S = Solution[\"S\"+str(self.test[k]+1)].values\n",
    "        if type(Prediction) in {list, np.array}:\n",
    "            P = Prediction[k].values\n",
    "        else:\n",
    "            P = Prediction[\"S\"+str(self.test[k]+1)].values\n",
    "        return error(P,S)\n",
    "    \n",
    "    def raw_error(self, k, Solution, Prediction, raw = err2):\n",
    "        \n",
    "        # Compute the non scaled error between the k-th solution and prediction\n",
    "        \n",
    "        if type(Solution) in {list, np.array}:\n",
    "            S = Solution[self.test[k]].values\n",
    "        else:\n",
    "            S = Solution[\"S\"+str(self.test[k]+1)].values\n",
    "        if Prediction == None:\n",
    "            return raw(np.zeros(S.shape), S)\n",
    "        elif type(Prediction) in {list, np.array}:\n",
    "            P = Prediction[k].values\n",
    "        else:\n",
    "            P = Prediction[\"S\"+str(self.test[k]+1)].values\n",
    "        return raw(P,S)\n",
    "    \n",
    "    def errors(self, Solution, Prediction, raw = err2, full = True, show = True, maxi = False, mini = False):\n",
    "        \n",
    "        # compute full errors between all solution and prediction\n",
    "        \n",
    "        er, l2, av_er, max_er, min_er = 0, 0, 0, 0, math.inf\n",
    "        error_list = []\n",
    "\n",
    "        for k in range(len(self.test)):\n",
    "            er += self.raw_error(k, Solution, Prediction)\n",
    "            l2 += self.raw_error(k, Solution, None)\n",
    "            one_er = self.one_error(k, Solution, Prediction)\n",
    "            av_er += one_er\n",
    "            error_list.append(one_er)\n",
    "            max_er = max(max_er, one_er)\n",
    "            min_er = min(min_er, one_er)\n",
    "        \n",
    "        if len(self.test) == 0: av_er = av_er\n",
    "        else: av_er = av_er/len(self.test)\n",
    "        \n",
    "        self.er = er\n",
    "        self.l2 = l2\n",
    "        self.av_er = av_er\n",
    "        self.max_er = max_er\n",
    "        self.min_er = min_er\n",
    "        self.std_er = np.std(error_list)\n",
    "        self.error_list = error_list\n",
    "        \n",
    "        if full:\n",
    "            if show: print(\"Total relative error for all test cases:\", er/l2)\n",
    "            return er/l2\n",
    "        else:\n",
    "            if show: print(\"Average error over all test cases:\", av_er)\n",
    "            if maxi: \n",
    "                print('')\n",
    "                print(\"Maximum relative error among test cases:\", max_er)\n",
    "            if mini: \n",
    "                print('')\n",
    "                print(\"Minimum relative error among test cases:\", min_er)\n",
    "            return av_er"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
