{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "err1 = lambda x, y: np.sqrt(mean_absolute_error(x,y))\n",
    "err2 = lambda x, y: np.sqrt(mean_squared_error(x,y))\n",
    "\n",
    "Error1 = lambda x, y: err1(x,y)/err1(np.zeros(y.shape), y)\n",
    "Error2 = lambda x, y: err2(x,y)/err2(np.zeros(y.shape), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment():\n",
    "\n",
    "    def __init__(self, t_f, x_f, t_l = None, x_l = None, algorithm = linear_model.LinearRegression()):\n",
    "\n",
    "        self.t_f = t_f # Position of time (or index axis) of the Model\n",
    "        self.x_f = x_f # Position of space (or column axis) of the Model\n",
    "        self.t_l = t_l # Position of time (or index axis) of the Labels (E.g. solution for SPDEs)\n",
    "        self.x_l = x_l # Position of space (or column axis) of the Labels (E.g. solution for SPDEs)\n",
    "\n",
    "        self.algorithm = algorithm # algorithm used for learning\n",
    "\n",
    "        self.F = None # Features df\n",
    "        self.L = None # Labels df\n",
    "        self.learning_model = None\n",
    "        self.train = None # list of features that are taken for training\n",
    "        self.test = None # list of features that are taken for testing\n",
    "        self.prediction = None # predicted values using the testing features\n",
    "        self.error = None # error for the current split\n",
    "        self.tangent = None # tangent for the current split\n",
    "\n",
    "    # Create a dataframe of features out of a Model.\n",
    "    def Create_Features(self, Models):\n",
    "        if Models is None:\n",
    "            print('Models are not given')\n",
    "            return\n",
    "        print('Creating features dataset.')\n",
    "        if type(Models) is list: # List of Models is given\n",
    "            num = len(Models) # number of realizations\n",
    "            trees = list(Models[0].keys())  # all the trees\n",
    "            X = Models[0][trees[0]].columns  # all the space points\n",
    "        else: # df of Models is given\n",
    "            num = Models.columns.levshape[0]\n",
    "            trees = [m[0] for m in Models[\"M1\"].columns[::Models[\"M1\"].columns.levshape[1]]]\n",
    "            X = Models[\"M1\"][trees[0]].columns\n",
    "\n",
    "        self.F = pd.DataFrame(index=np.arange(num), columns=trees)  # Features data of model\n",
    "        \n",
    "        for i in tqdm(range(num)): # i-th datapoint of the model\n",
    "            if type(Models) is list:\n",
    "                self.F.iloc[i] = [Models[i][A][X[self.x_f]].iloc[self.t_f] for A in trees]\n",
    "            else:\n",
    "                self.F.iloc[i] = [Models['M' + str(i + 1)][A][X[self.x_f]].iloc[self.t_f] for A in trees]\n",
    "\n",
    "    # Create a df of labels out of results\n",
    "    def Create_Labels(self, Results):\n",
    "        if Results is None:\n",
    "            print('Results are not given')\n",
    "            return\n",
    "        \n",
    "        if self.t_l == None and self.x_l == None: # If t_l = x_l = None then consider Results as a label dataframe\n",
    "            self.L = Results\n",
    "        else:\n",
    "            print('Creating labels dataset.')\n",
    "            num = Results.shape[0]\n",
    "            self.L = pd.DataFrame(index=np.arange(num), columns=['(' + str(self.t_l) + ',' + str(self.x_l) + ')'])\n",
    "            \n",
    "            for i in tqdm(range(num)):  # i-th datapoint of the results\n",
    "                if self.t_l == None:\n",
    "                    self.L.iloc[i] = Results[i][-1,self.x_l]\n",
    "                elif self.x_l == None:\n",
    "                    self.L.iloc[i] = Results[i][self.t_l, self.x_f]\n",
    "                else:\n",
    "                    self.L.iloc[i] = Results[i][self.t_l, self.x_l]\n",
    "\n",
    "    # Perform learning of the solution from the model at a space-time point (m, n_S).\n",
    "    # By default learning algorithm is linear regression.\n",
    "    def one_experiment(self, Models = None, Results = None, split = True,  test_size=0.3, columns = None):\n",
    "\n",
    "        if self.F is None:\n",
    "            self.Create_Features(Models)\n",
    "        if self.L is None:\n",
    "            self.Create_Labels(Results)\n",
    "        if columns is None:\n",
    "            columns = self.F.columns\n",
    "\n",
    "        # split data into test and train\n",
    "        if split:\n",
    "            X_train, X_test, y_train, _ = train_test_split(self.F[columns], self.L, test_size=test_size)\n",
    "            self.test, self.train = list(X_test.index), list(X_train.index)\n",
    "        else:\n",
    "            X_train, X_test, y_train = self.F.iloc[self.train], self.F.iloc[self.test], self.L.iloc[self.train]\n",
    "\n",
    "        self.learning_model = self.algorithm.fit(X_train, y_train)  # fit the model with train data\n",
    "        self.prediction = self.learning_model.predict(X_test)  # compute the prediction\n",
    "    \n",
    "    def show_regression_experiment(self, metric = err2, normalise = True):\n",
    "\n",
    "        if self.learning_model is None:\n",
    "            print('There is no learning model created')\n",
    "            return\n",
    "\n",
    "        real = self.L.loc[self.test].values# actual values\n",
    "        # compute the regression line between predicted and real data. I.e. prediction = a*real + b\n",
    "        # Ideal scenario is when a = 1, b = 0\n",
    "        fitting = linear_model.LinearRegression().fit(real, self.prediction.reshape(real.shape))\n",
    "        b, a = fitting.intercept_, fitting.coef_\n",
    "        y_min, y_max = min(self.prediction), max(self.prediction)\n",
    "        x_min, x_max = min(real), max(real)\n",
    "        size_y, size_x = np.abs(y_max-y_min), np.abs(x_max-x_min)\n",
    "        self.tangent = a[0][0]\n",
    "        fig = plt.figure(figsize=(14, 9))\n",
    "        plt.scatter(real, self.prediction)\n",
    "        plt.plot(real, b + real * a, 'r', label='Regression line between predicted and u(t,x)')\n",
    "        plt.plot(real, real, 'g', label='y=x line')\n",
    "        #plt.title(\"Comparison of predicted vs actual values of u(t,x).\", fontsize=20)\n",
    "        plt.xlabel(\"Values of u(t,x)\", fontsize=20)\n",
    "        plt.ylabel(\"Predicted Values\", fontsize=20)\n",
    "        plt.legend(loc=2, prop={'size': 15})\n",
    "        plt.show();\n",
    "        \n",
    "        # If metric for computing an error is given, compute errors. By default error is an l^2 error normalised\n",
    "        if metric:  # compute error\n",
    "            if normalise: # normalise metric\n",
    "                self.error = metric(self.prediction, real)/(metric(np.zeros(len(real)), real))\n",
    "            else:\n",
    "                self.error = metric(self.prediction, real)\n",
    "            print(\"Error:\", self.error, \". Tangent:\", a[0][0])\n",
    "        return\n",
    "\n",
    "    def regression_error(self, metric = err2, normalise = True):\n",
    "\n",
    "        if self.learning_model is None:\n",
    "            print('There is not model created.')\n",
    "            return\n",
    "\n",
    "        real = self.L.loc[self.test].values\n",
    "        fitting = linear_model.LinearRegression().fit(real, self.prediction)\n",
    "        self.tangent = fitting.coef_[0][0]\n",
    "        \n",
    "        if normalise:\n",
    "            self.error = metric(self.prediction, real)/(metric(np.zeros(len(real)), real))\n",
    "        else:\n",
    "            self.error = metric(self.prediction, real)\n",
    "        return self.error, self.tangent\n",
    "\n",
    "    # Perform several experiments to deduce the average error and a slope for this model\n",
    "    def many_regression_experiments(self, num, Models = None, Results = None, test_size=0.3, metric = err2, normalise = True, columns = None, mini = False, full = False):\n",
    "\n",
    "        errors, tangents = [], []\n",
    "\n",
    "        for i in tqdm(range(num)):\n",
    "            self.one_experiment(Models, Results, test_size = test_size, columns = columns)\n",
    "            e, a = self.regression_error(metric = metric, normalise = normalise)\n",
    "            errors.append(e)\n",
    "            tangents.append(a)\n",
    "        if mini:\n",
    "            return min(errors), min(tangents)\n",
    "        if full:\n",
    "            return errors, tangents\n",
    "        \n",
    "        return sum(errors)/len(errors), sum(tangents)/len(errors)\n",
    "\n",
    "    def save_Features(self, name):\n",
    "        if self.F is None:\n",
    "            print('Features are not created yet.')\n",
    "        else:\n",
    "            self.F.to_csv(name)\n",
    "\n",
    "    def save_Labels(self, name):\n",
    "        if self.F is None:\n",
    "            print('Labels are not created yet.')\n",
    "        else:\n",
    "            self.L.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
